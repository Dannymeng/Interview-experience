# 面经1


作者：ForrestGump-彭
链接：[https://www.nowcoder.com/discuss/120918?type=2](https://www.nowcoder.com/discuss/120918?type=2)
来源：牛客网

秋招终于告一段落了，期间看了很多笔经面经，十分感谢大家，写一篇大数据开发的面经，因为这方面的面经实在太少了，最近还多了一些，在当初看书复习期间，基本10个面经里面只有一个跟大数据有关，而这一篇里还包括着大数据算法和数据分析。所以一开始学的时候很痛苦，有点不知道怎么看，看什么，所以写这个就是给以后想要做大数据开发的人看，大神就可以绕路了。

大数据招聘的岗位主要分为三个，一个是大数据算法，也就是机器学习一类的（今年报这个的人数爆炸，工资很高但是也有一定的难度，对数学要求相对高一些，我一开始恬不知耻的还尝试了一下，后来被劝退了，老老实实研究大数据开发）。接下来是大数据开发，主要是，开发/使用/重写-----Spark/Hadoop类的组件（相关组件很多，可以根据自己的项目或者兴趣进行学习，具体后面说），使之可以适应各个公司的不同业务需求，所以要对spark/Hadoop组件，以及处理大量数据的方法有一定的了解。最后就是数据分析，数据分析很多公司招聘的岗位大多是要熟练使用SQL/Excel等，也就是使用各种工具进行数据的分析（要求相对低一些，很多非计算机专业的也都投了这个岗位）。

接下来具体说一下大数据开发我们都需要准备些什么：

因为大数据开发是夹在后台开发和机器学习之间的，所以需要看的东西会多一些，薪资也同样夹在两者之间。

笔试阶段

1.大数据开发的笔试，大多数公司的题是跟java/后台开发一套题，所以首先就要了解后台开发的相关知识：计算机网络，***作系统，java，数据结构，数据库，最好还要会点C/C++。当不是一套题的时候就要了解spark/Hadoop组件相关知识，基本的机器学习算法，以及SQL语句。

所以很多做java后台开发的其实可以看个一两个月相关知识就可以去面试大数据开发岗位了，我其实一开始学的就是java，因为硕士之前两年都是使用spark/Hadoop做导师的项目，所以才报的大数据开发。

2.当过了笔试以后，我们就要应付接下来的面试，具体说面试之前，强调一下算法的重要性，这个算法不是大数据算法， 而是常规“撕算法”的算法，因为这个无论是笔试面试都十分重要，在面试的最后阶段基本都会写一写算法，最简单的就是各种排序，难一点就是各种剑指offer的类型题，跟深入一些的话，动态规划，消费者生产者模式，手写一个线程池等等（具体这些就可以去java面经里面看都会撕什么算法了），算法相关问题下面就不再说了，但是再强调一下真的是十分重要，即使前面的所有知识你回答的天衣无缝，但是只要撕算法的时候没写出来，就基本gg了。

面经：

主要分两部分，项目部分和问答部分

项目部分：

一定要有一两个拿的出手的项目，可以是自己在网上学的，导师项目，以及各种比赛的项目，如果你的项目够吊，凭项目你就可以进阿里，我有个同学就是这样，基础知识一般，但是老师项目厉害（各种奖，还被央视报道过），阿里三面全程问项目，就拿到了offer。多说一句找工作是个很玄的东西，天时地利人和才行，基本运气成分和你的能力五五开（我指的是多数人，大神不存在这个问题）。项目一定要了解到不能再被人问出问题的程度，也就是说你可以给一个一点不懂的人讲明白，那你项目这一块就OK了，准备的时候就可以找一两个不是你这个方向的好朋友给他们讲讲，他们都懂了，面试就可以了。

问答部分：（简历要写明白自己会什么，细一点，面试官才“有可能”会按着你写的东西问你，要不然问你啥就不一定了，只有你想不到，没有他不会问的）

1.java面经中除了框架相关的知识都要准备，最常问的就是JVM，gc，多线程，设计模式，各种容器，去看java面经，牛客一堆。

2.组件相关：

相关组件了解哪些？spark/hbase/Hive/Yarn/zookeeper/mapreduce/kafka/HDFS这些常见组件中最好了解3个以上。

spark：

1.RDD的懒加载怎么回事，RDD怎么更新，RDD都有什么***作，区别是啥，举几个例子。

2.spark是怎么工作的，和Hadoop区别，能不能替代Hadoop。

3.stage是如何划分的。

4.groupbykey,reducebyke有什么区别。

5.混洗是干啥的，如何解决数据倾斜。

6.分区的算法，池塘抽样等。

7.如何优化参数之类的

看了不少书和博客。

hbase:

如何设计rowkey，region是怎么回事，怎么划分的，怎么定位的，写***作是怎么样的，什么情况下会刷写，wal是干啥用的，为啥要有这个东西存在，cap理论，这里我是看了一本叫hbase不睡觉的书，基本一天看完，基本就都了解了。

HDFS：

这个就要了解的详细点，是怎么存数据的，怎么对数据分块的，怎么读取数据的，都有什么控制的节点，各自都是做什么用的等等。断电的话怎么办，哪些数据丢失。。

Yarn:

有什么模式，模式之间的区别，yarn都是由什么组件组成的，都是干啥的。

mapreduce:

大数据开发最基本的原理，这个如果不理解那还是别做大数据开发了。

Kafka/zookeeper：

大家自己找些书看看，面试的时候被问过几个问题，我项目没用过这些，只是后来看了看博客，现在的问题也基本忘了，抱歉了。

大数据类的算法：

在一个不断产生的流式数据中，如何保证每次取到的数据尽可能的随机。

topk问题

100个数，如何打乱，要求最乱。

以上所有的时间复杂度。

其实这些知识是被问过的问题中的一半吧，好多都忘了，怪我当时面试完没做笔记，先这样吧，想起什么我再来补充。


