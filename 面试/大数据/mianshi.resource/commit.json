{"compress":true,"commitItems":[["38021ef1-8db1-4860-b0a5-9d1edb0ee29e",1555346589796,"",[[1555346532430,["28447@DESKTOP-BE7HQ26",[[1,0,"# mianshi\n\n\n\n"]],[0,0],[12,12]]],[1555346533413,["28447@DESKTOP-BE7HQ26",[[1,12,"大数据面试    张浩\n\n**策略**\n\n1.  抛砖引玉\n\n2.  反客为主\n\n（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）\n\n用A4纸写把项目的部分写下来\n\n**项目介绍部分：**\n\n1.  架构设计（画图）\n\n2.  组件选择（调研+压测）\n\n3.  集群规模\n\n4.  高可靠的实现\n\n5.  压缩格式\n\n6.  文件格式\n\n7.  每秒、每分钟数据量   离线、实时的数据量\n\n8.  哪块高可靠没有做（ flume memory | spark yarn 调优）\n\n9.  集群调优（硬件、Linux、JVM、CDH、HDFS）\n\n开发内容：\n\n1.  Spark、Hive\n\n2.  存储\n\n3.  监控（运维）\n\n补充：\n\n1.  Hive、Spark调优\n\n2.  Bug怎么去解决\n\n3.  算法\n\n4.  机器学习\n\n5.  仓库\n\n6.  YARN怎么调优\n\n7.  CDH资源池\n\n**Java部分**\n\n1.  GC、JVM垃圾选择器参数\n\n2.  Java值传递与对象传递的区别\n\n3.  Java的多继承、多态\n\n4.  Java的sleep和wait的区别\n\n5.  HashMap和HashTable的区别\n\n6.  Java的多线程有哪几种形式\n\n7.  Java接口和抽象类的区别\n\n**大数据部分：**\n\n1.  HDFS读写流程\n\n2.  YARN怎么调整Memory和CPU的资源\n\n3.  MR作业和Spark作业在YARN的流程 \n\n1.  Hive的分组排序\n\n2.  Hive的自定义函数\n\n3.  Hive的left join、left outer join和left semi join的主要区别\n\n1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)\n\n2.  Spark RDD的五大特性\n\n3.  Spark读取Kafka的两种方式，两者区别\n\n4.  Spark调优\n\n5.  数据倾斜\n\n6.  压缩格式\n\n7.  文件格式\n\n     **大数据项目部分**\n\n1.  集群的规模\n\n2.  每秒、每分钟、每小时、每天的吞吐量\n\n3.  一个作业多大？多少资源？多久跑完\n\n4.  如何设置作业的资源\n\n5.  高可靠\n\n6.  生产的优化\n\n     **其他**\n\n1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题\n\n2.  进去公司的时候工资一定要要到位\n\n3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题\n\n4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”"]],[12,12],[1394,1394]]]],null,"28447@DESKTOP-BE7HQ26"],["07ef2821-bb34-430c-a8d8-c1ee96412c2c",1555642702968,"# mianshi\n\n\n大数据面试    张浩\n\n**策略**\n\n1.  抛砖引玉\n\n2.  反客为主\n\n（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）\n\n用A4纸写把项目的部分写下来\n\n**项目介绍部分：**\n\n1.  架构设计（画图）\n\n2.  组件选择（调研+压测）\n\n3.  集群规模\n\n4.  高可靠的实现\n\n5.  压缩格式\n\n6.  文件格式\n\n7.  每秒、每分钟数据量   离线、实时的数据量\n\n8.  哪块高可靠没有做（ flume memory | spark yarn 调优）\n\n9.  集群调优（硬件、Linux、JVM、CDH、HDFS）\n\n开发内容：\n\n1.  Spark、Hive\n\n2.  存储\n\n3.  监控（运维）\n\n补充：\n\n1.  Hive、Spark调优\n\n2.  Bug怎么去解决\n\n3.  算法\n\n4.  机器学习\n\n5.  仓库\n\n6.  YARN怎么调优\n\n7.  CDH资源池\n\n**Java部分**\n\n1.  GC、JVM垃圾选择器参数\n\n2.  Java值传递与对象传递的区别\n\n3.  Java的多继承、多态\n\n4.  Java的sleep和wait的区别\n\n5.  HashMap和HashTable的区别\n\n6.  Java的多线程有哪几种形式\n\n7.  Java接口和抽象类的区别\n\n**大数据部分：**\n\n1.  HDFS读写流程\n\n2.  YARN怎么调整Memory和CPU的资源\n\n3.  MR作业和Spark作业在YARN的流程 \n\n1.  Hive的分组排序\n\n2.  Hive的自定义函数\n\n3.  Hive的left join、left outer join和left semi join的主要区别\n\n1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)\n\n2.  Spark RDD的五大特性\n\n3.  Spark读取Kafka的两种方式，两者区别\n\n4.  Spark调优\n\n5.  数据倾斜\n\n6.  压缩格式\n\n7.  文件格式\n\n     **大数据项目部分**\n\n1.  集群的规模\n\n2.  每秒、每分钟、每小时、每天的吞吐量\n\n3.  一个作业多大？多少资源？多久跑完\n\n4.  如何设置作业的资源\n\n5.  高可靠\n\n6.  生产的优化\n\n     **其他**\n\n1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题\n\n2.  进去公司的时候工资一定要要到位\n\n3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题\n\n4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”\n",[[1555642690739,["28447@DESKTOP-BE7HQ26",[[-1,18,"   "],[1,21,"   "],[-1,208," "],[1,209," "],[1,499,"抽象类"],[-1,500,""],[-1,666," "],[1,667," "],[-1,804," "],[1,805," "],[-1,1090,"     "],[1,1095,"     "],[-1,1199,"     "],[1,1204,"     "]],[499,499],[502,502]]],[1555642692847,["28447@DESKTOP-BE7HQ26",[[1,499,"java"]],[499,499],[503,503]]],[1555642694542,["28447@DESKTOP-BE7HQ26",[[1,506,"是"]],[506,506],[507,507]]],[1555642704924,["28447@DESKTOP-BE7HQ26",[[1,509,"类"]],[509,509],[510,510]]],[1555642705762,["28447@DESKTOP-BE7HQ26",[[-1,509,"类"]],[510,510],[509,509]]],[1555642741092,["28447@DESKTOP-BE7HQ26",[[1,509,"子类的一般特性，抽象类是被用来创建继承层级里子类的模板"]],[509,509],[536,536]]],[1555642742764,["28447@DESKTOP-BE7HQ26",[[1,537,"\n"]],[536,536],[537,537]]],[1555642748851,["28447@DESKTOP-BE7HQ26",[[-1,499,"java抽象类是捕捉子类的一般特性，抽象类是被用来创建继承层级里子类的模板"]],[499,536],[499,499]]],[1555642750154,["28447@DESKTOP-BE7HQ26",[[1,589,"8. \n"]],[588,588],[592,592]]],[1555642750498,["28447@DESKTOP-BE7HQ26",[[1,592,"java抽象类是捕捉子类的一般特性，抽象类是被用来创建继承层级里子类的模板"]],[592,592],[629,629]]],[1555642753985,["28447@DESKTOP-BE7HQ26",[[-1,589,"8. "]],[589,592],[589,589]]],[1555642756036,["28447@DESKTOP-BE7HQ26",[[1,626,"；"]],[626,626],[627,627]]],[1555642756394,["28447@DESKTOP-BE7HQ26",[[1,629,"\n"]],[627,627],[628,628]]],[1555642759403,["28447@DESKTOP-BE7HQ26",[[1,628,"接口是"]],[628,628],[631,631]]],[1555642821892,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,631,"*\n"],[1,633,"\n\n**"]],[499,499],[637,637]]],[1555642821892,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,631,"*\n"],[-1,631,"\n\n**"]],[637,637],[499,499]]],[1555642763738,["28447@DESKTOP-BE7HQ26",[[1,589,"- "]],[589,589],[591,591]]],[1555642766042,["28447@DESKTOP-BE7HQ26",[[1,630,"- "]],[630,630],[632,632]]],[1555642871759,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,635,"*\n"],[1,637,"\n\n**"]],[499,499],[641,641]]],[1555642871759,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,635,"*\n"],[-1,635,"\n\n**"]],[641,641],[499,499]]],[1555642864681,["28447@DESKTOP-BE7HQ26",[[1,635,"接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。"]],[635,635],[708,708]]],[1555642867489,["28447@DESKTOP-BE7HQ26",[[-1,635,"接口是"]],[632,635],[632,632]]],[1555642870905,["28447@DESKTOP-BE7HQ26",[[-1,591,"java"]],[592,595],[591,591]]],[1555642889803,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,701,"*\n"],[1,703,"\n\n**"]],[499,499],[707,707]]],[1555642889803,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,701,"*\n"],[-1,701,"\n\n**"]],[707,707],[499,499]]],[1555642872816,["28447@DESKTOP-BE7HQ26",[[1,702,"- \n"]],[701,701],[704,704]]],[1555642873009,["28447@DESKTOP-BE7HQ26",[[-1,702,"- "]],[704,704],[703,703]]],[1555642877952,["28447@DESKTOP-BE7HQ26",[[1,703,"什么时候是同"]],[703,703],[709,709]]],[1555642879144,["28447@DESKTOP-BE7HQ26",[[-1,707,"是同"]],[709,709],[707,707]]],[1555642883582,["28447@DESKTOP-BE7HQ26",[[1,707,"使用抽象列"]],[707,707],[712,712]]],[1555642884881,["28447@DESKTOP-BE7HQ26",[[-1,711,"列"]],[712,712],[711,711]]],[1555642889047,["28447@DESKTOP-BE7HQ26",[[1,711,"类和接口："]],[711,711],[716,716]]],[1555642889225,["28447@DESKTOP-BE7HQ26",[[1,717,"\n"]],[716,716],[717,717]]],[1555642949814,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,701,"*"],[1,702,"\n"],[1,718,"**"]],[499,499],[720,720]]],[1555642949814,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,701,"*"],[-1,701,"\n"],[-1,718,"**"]],[720,720],[499,499]]],[1555642902940,["28447@DESKTOP-BE7HQ26",[[1,717,"*   如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。\n*   如果你想实现多重继承，那么你必须使用接口。由于**Java不支持多继承**，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。\n*   如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。"]],[717,717],[897,897]]],[1555642921849,["28447@DESKTOP-BE7HQ26",[[1,899," \n*"]],[897,897],[900,900]]],[1555642922056,["28447@DESKTOP-BE7HQ26",[[-1,898,"* "]],[900,900],[899,899]]],[1555642943090,["28447@DESKTOP-BE7HQ26",[[1,702,"- \n"]],[701,701],[704,704]]],[1555642943514,["28447@DESKTOP-BE7HQ26",[[-1,702,"- "]],[704,704],[703,703]]],[1555642944042,["28447@DESKTOP-BE7HQ26",[[1,703,"| **参数** | **抽象类** | **接口** |\n| 默认的方法实现 | 它可以有默认的方法实现 | 接口完全是抽象的。它根本不存在方法的实现 |\n| 实现 | 子类使用**extends**关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。 | 子类使用关键字**implements**来实现接口。它需要提供接口中所有声明的方法的实现 |\n| 构造器 | 抽象类可以有构造器 | 接口不能有构造器 |\n| 与正常Java类的区别 | 除了你不能实例化抽象类之外，它和普通Java类没有任何区别 | 接口是完全不同的类型 |\n| 访问修饰符 | 抽象方法可以有**public**、**protected**和**default**这些修饰符 | 接口方法默认修饰符是**public**。你不可以使用其它修饰符。 |\n| main方法 | 抽象方法可以有main方法并且我们可以运行它 | 接口没有main方法，因此我们不能运行它。 |\n| 多继承 | 抽象方法可以继承一个类和实现多个接口 | 接口只可以继承一个或多个其它接口 |\n| 速度 | 它比接口速度要快 | 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。 |\n| 添加新方法 | 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 | 如果你往接口中添加方法，那么你必须改变实现该接口的类。 |"]],[703,703],[1329,1329]]],[1555642990077,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,701,"*"],[1,702,"\n"],[1,1527,"*大"]],[499,499],[1529,1529]]],[1555642990077,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,701,"*"],[-1,701,"\n"],[-1,1527,"*大"]],[1529,1529],[499,499]]],[1555642952194,["28447@DESKTOP-BE7HQ26",[[1,733,"\n"]],[732,732],[733,733]]],[1555642953901,["28447@DESKTOP-BE7HQ26",[[-1,733,"\n"]],[733,733],[732,732]]],[1555642961141,["28447@DESKTOP-BE7HQ26",[[1,705,"item      | Model    |  Price | Qty |\n| --------- | -------- | -----: | --: |\n| Laptop    | 13\" Pro  | $1,300 |   1 |\n| Phone     | Plus     |   $800 |   2 |\n| Watch     | Series 3 |   $400 |   3 |\n| Headphone | HD650    |   $350 |   2 |\n\n| "]],[702,702],[944,944]]],[1555642968466,["28447@DESKTOP-BE7HQ26",[[1,974,"\n"]],[973,973],[974,974]]],[1555642968772,["28447@DESKTOP-BE7HQ26",[[1,974,"| --------- | -------- | -----: | --: |"]],[974,974],[1013,1013]]],[1555642978283,["28447@DESKTOP-BE7HQ26",[[-1,1007," --: |"]],[1007,1013],[1007,1007]]],[1555643050088,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,701,"*"],[1,702,"\n"],[1,1802,"*大"]],[499,499],[1804,1804]]],[1555643050088,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,701,"*"],[-1,701,"\n"],[-1,1802,"*大"]],[1804,1804],[499,499]]],[1555643018921,["28447@DESKTOP-BE7HQ26",[[-1,1004,":"]],[1005,1005],[1004,1004]]],[1555643028466,["28447@DESKTOP-BE7HQ26",[[1,976,"："]],[976,976],[977,977]]],[1555643030835,["28447@DESKTOP-BE7HQ26",[[-1,976,"："]],[977,977],[976,976]]],[1555643031864,["28447@DESKTOP-BE7HQ26",[[1,976,":"]],[976,976],[977,977]]],[1555643035968,["28447@DESKTOP-BE7HQ26",[[-1,982,"---- "]],[981,981],[982,982]]],[1555643036542,["28447@DESKTOP-BE7HQ26",[[1,982,":"]],[982,982],[983,983]]],[1555643039885,["28447@DESKTOP-BE7HQ26",[[1,985,":"]],[985,985],[986,986]]],[1555643042333,["28447@DESKTOP-BE7HQ26",[[1,994,":"]],[994,994],[995,995]]],[1555643043771,["28447@DESKTOP-BE7HQ26",[[1,998,":"]],[998,998],[999,999]]],[1555643045916,["28447@DESKTOP-BE7HQ26",[[1,1004,":"]],[1004,1004],[1005,1005]]],[1555643110096,[null,[[-1,499,".\n"],[1,501,"\n\n4."],[-1,587,"\n*"],[-1,701,"*"],[1,702,"\n"],[1,1802,"*大"]],[499,499],[1804,1804]]],[1555643110096,[null,[[1,499,".\n"],[-1,499,"\n\n4."],[1,589,"\n*"],[1,701,"*"],[-1,701,"\n"],[-1,1802,"*大"]],[1804,1804],[499,499]]],[1555643076120,["28447@DESKTOP-BE7HQ26",[[-1,703,"| item      | Model    |  Price | Qty |\n| --------- | -------- | -----: | --: |\n| Laptop    | 13\" Pro  | $1,300 |   1 |\n| Phone     | Plus     |   $800 |   2 |\n| Watch     | Series 3 |   $400 |   3 |\n| Headphone | HD650    |   $350 |   2 |"]],[703,942],[703,703]]],[1555643077114,["28447@DESKTOP-BE7HQ26",[[-1,704,"\n"]],[703,703],[702,702]]],[1555643077992,["28447@DESKTOP-BE7HQ26",[[-1,703,"\n"]],[702,702],[701,701]]]],null,"28447@DESKTOP-BE7HQ26"],["a333affe-78b5-4f0c-9cfe-4553ed040bf6",1555724244964,"# mianshi\n\n\n大数据面试    张浩\n\n**策略**\n\n1.  抛砖引玉\n\n2.  反客为主\n\n（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）\n\n用A4纸写把项目的部分写下来\n\n**项目介绍部分：**\n\n1.  架构设计（画图）\n\n2.  组件选择（调研+压测）\n\n3.  集群规模\n\n4.  高可靠的实现\n\n5.  压缩格式\n\n6.  文件格式\n\n7.  每秒、每分钟数据量   离线、实时的数据量\n\n8.  哪块高可靠没有做（ flume memory | spark yarn 调优）\n\n9.  集群调优（硬件、Linux、JVM、CDH、HDFS）\n\n开发内容：\n\n1.  Spark、Hive\n\n2.  存储\n\n3.  监控（运维）\n\n补充：\n\n1.  Hive、Spark调优\n\n2.  Bug怎么去解决\n\n3.  算法\n\n4.  机器学习\n\n5.  仓库\n\n6.  YARN怎么调优\n\n7.  CDH资源池\n\n**Java部分**\n\n1.  GC、JVM垃圾选择器参数\n\n2.  Java值传递与对象传递的区别\n\n3.  Java的多继承、多态\n\n\n4.  Java的sleep和wait的区别\n\n5.  HashMap和HashTable的区别\n\n6.  Java的多线程有哪几种形式\n\n7.  Java接口和抽象类的区别\n- 抽象类是捕捉子类的一般特性，抽象类是被用来创建继承层级里子类的模板；\n- 接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。\n\n| **参数** | **抽象类** | **接口** |\n| :-----:| :--------: | :-----: |\n| 默认的方法实现 | 它可以有默认的方法实现 | 接口完全是抽象的。它根本不存在方法的实现 |\n| 实现 | 子类使用**extends**关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。 | 子类使用关键字**implements**来实现接口。它需要提供接口中所有声明的方法的实现 |\n| 构造器 | 抽象类可以有构造器 | 接口不能有构造器 |\n| 与正常Java类的区别 | 除了你不能实例化抽象类之外，它和普通Java类没有任何区别 | 接口是完全不同的类型 |\n| 访问修饰符 | 抽象方法可以有**public**、**protected**和**default**这些修饰符 | 接口方法默认修饰符是**public**。你不可以使用其它修饰符。 |\n| main方法 | 抽象方法可以有main方法并且我们可以运行它 | 接口没有main方法，因此我们不能运行它。 |\n| 多继承 | 抽象方法可以继承一个类和实现多个接口 | 接口只可以继承一个或多个其它接口 |\n| 速度 | 它比接口速度要快 | 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。 |\n| 添加新方法 | 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 | 如果你往接口中添加方法，那么你必须改变实现该接口的类。 |\n什么时候使用抽象类和接口：\n*   如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。\n*   如果你想实现多重继承，那么你必须使用接口。由于**Java不支持多继承**，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。\n*   如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。\n\n**大数据部分：**\n\n1.  HDFS读写流程\n\n2.  YARN怎么调整Memory和CPU的资源\n\n3.  MR作业和Spark作业在YARN的流程 \n\n1.  Hive的分组排序\n\n2.  Hive的自定义函数\n\n3.  Hive的left join、left outer join和left semi join的主要区别\n\n1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)\n\n2.  Spark RDD的五大特性\n\n3.  Spark读取Kafka的两种方式，两者区别\n\n4.  Spark调优\n\n5.  数据倾斜\n\n6.  压缩格式\n\n7.  文件格式\n\n     **大数据项目部分**\n\n1.  集群的规模\n\n2.  每秒、每分钟、每小时、每天的吞吐量\n\n3.  一个作业多大？多少资源？多久跑完\n\n4.  如何设置作业的资源\n\n5.  高可靠\n\n6.  生产的优化\n\n     **其他**\n\n1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题\n\n2.  进去公司的时候工资一定要要到位\n\n3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题\n\n4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”\n",[[1555724203116,["28447@DESKTOP-BE7HQ26",[[1,1989,"3. \n"]],[1988,1988],[1992,1992]]],[1555724203284,["28447@DESKTOP-BE7HQ26",[[-1,1989,"3. "]],[1992,1992],[1990,1990]]],[1555724204231,["28447@DESKTOP-BE7HQ26",[[1,1991,"\n"]],[1990,1990],[1991,1991]]],[1555724204416,["28447@DESKTOP-BE7HQ26",[[1,1992,"\n"]],[1991,1991],[1992,1992]]],[1555724207578,["28447@DESKTOP-BE7HQ26",[[1,1993,"\n"]],[1989,1989],[1990,1990]]],[1555724588248,["28447@DESKTOP-BE7HQ26",[[1,1990,"- 1. 1.A list of partitions"]],[1990,1990],[2017,2017]]],[1555724594752,["28447@DESKTOP-BE7HQ26",[[-1,1992,"1. "]],[1994,1994],[1991,1991]]],[1555724599027,["28447@DESKTOP-BE7HQ26",[[1,1994," "]],[1994,1994],[1995,1995]]],[1555724602712,["28447@DESKTOP-BE7HQ26",[[-1,1989,"\n"]],[1990,1990],[1989,1989]]],[1555724603891,["28447@DESKTOP-BE7HQ26",[[1,1989,"  "]],[1989,1989],[1991,1991]]],[1555724604875,["28447@DESKTOP-BE7HQ26",[[1,1991," "]],[1991,1991],[1992,1992]]],[1555724607825,["28447@DESKTOP-BE7HQ26",[[1,2018,"   - \n"]],[2017,2017],[2023,2023]]],[1555724609118,["28447@DESKTOP-BE7HQ26",[[1,2023,"爱神的箭"]],[2023,2023],[2027,2027]]],[1555724610432,["28447@DESKTOP-BE7HQ26",[[-1,2022," 爱神的箭"]],[2027,2027],[2022,2022]]],[1555724611224,["28447@DESKTOP-BE7HQ26",[[1,2022," "]],[2022,2022],[2023,2023]]],[1555724615882,["28447@DESKTOP-BE7HQ26",[[1,2024,"   - \n"]],[2017,2017],[2023,2023]]],[1555724617938,["28447@DESKTOP-BE7HQ26",[[-1,2021,"- "]],[2023,2023],[2021,2021]]],[1555724625946,["28447@DESKTOP-BE7HQ26",[[1,2021,"RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）"]],[2021,2021],[2118,2118]]],[1555724643574,["28447@DESKTOP-BE7HQ26",[[1,2124,"A function for computing each split"]],[2124,2124],[2159,2159]]],[1555724646354,["28447@DESKTOP-BE7HQ26",[[1,2160,"   - \n   - \n"]],[2159,2159],[2165,2165]]],[1555724647458,["28447@DESKTOP-BE7HQ26",[[-1,2163,"- "]],[2165,2165],[2163,2163]]],[1555724655076,["28447@DESKTOP-BE7HQ26",[[1,2163,"RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。"]],[2163,2163],[2224,2224]]],[1555724665895,["28447@DESKTOP-BE7HQ26",[[1,2230,"A list of dependencies on other RDDs\n\nRDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。"]],[2230,2230],[2332,2332]]],[1555724668865,["28447@DESKTOP-BE7HQ26",[[-1,2267,"\n"]],[2268,2268],[2267,2267]]],[1555724672416,["28447@DESKTOP-BE7HQ26",[[1,2267,"    "]],[2267,2267],[2271,2271]]],[1555724674506,["28447@DESKTOP-BE7HQ26",[[1,2336,"    \n"]],[2335,2335],[2340,2340]]],[1555724676321,["28447@DESKTOP-BE7HQ26",[[1,2340,"- "]],[2340,2340],[2342,2342]]],[1555724679074,["28447@DESKTOP-BE7HQ26",[[-1,2338,"  "]],[2340,2340],[2338,2338]]],[1555724695187,["28447@DESKTOP-BE7HQ26",[[1,2340,"Optionally,a Partitioner for Key-value RDDs\n  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面\n--------------------- \n作者：书灯 \n来源：CSDN \n原文：https://blog.csdn.net/struct_slllp_main/article/details/76209056 \n版权声明：本文为博主原创文章，转载请附上博文链接！"]],[2340,2340],[2643,2643]]],[1555724698906,["28447@DESKTOP-BE7HQ26",[[-1,2510,"--------------------- \n作者：书灯 \n来源：CSDN \n原文：https://blog.csdn.net/struct_slllp_main/article/details/76209056 \n版权声明：本文为博主原创文章，转载请附上博文链接！\n"]],[2510,2644],[2510,2510]]],[1555724707996,["28447@DESKTOP-BE7HQ26",[[-1,2384," "],[1,2385," "],[1,2510,"  - Optionally, a list of preferred locations to compute each split on\n\n最优的位置去计算，也就是数据的本地性。"]],[2510,2510],[2601,2601]]],[1555724712230,["28447@DESKTOP-BE7HQ26",[[1,2582,"****"]],[2582,2582],[2584,2584]]],[1555724715337,["28447@DESKTOP-BE7HQ26",[[-1,2586,"最优的位置"]],[2586,2591],[2586,2586]]],[1555724716428,["28447@DESKTOP-BE7HQ26",[[1,2584,"最优的位置"]],[2584,2584],[2589,2589]]],[1555724718402,["28447@DESKTOP-BE7HQ26",[[-1,2581,"\n"]],[2582,2582],[2581,2581]]],[1555724720187,["28447@DESKTOP-BE7HQ26",[[1,2581,"    "]],[2581,2581],[2585,2585]]],[1555724721971,["28447@DESKTOP-BE7HQ26",[[-1,2601,"数据的本地性"]],[2601,2607],[2601,2601]]],[1555724723097,["28447@DESKTOP-BE7HQ26",[[1,2601,"****"]],[2601,2601],[2603,2603]]],[1555724723395,["28447@DESKTOP-BE7HQ26",[[1,2603,"数据的本地性"]],[2603,2603],[2609,2609]]],[1555724746112,["28447@DESKTOP-BE7HQ26",[[1,2124,"2. "]],[2124,2124],[2127,2127]]],[1555724749464,["28447@DESKTOP-BE7HQ26",[[1,2233,"3. "]],[2233,2233],[2236,2236]]],[1555724753656,["28447@DESKTOP-BE7HQ26",[[1,2346,"4. "]],[2346,2346],[2349,2349]]],[1555724757319,["28447@DESKTOP-BE7HQ26",[[1,2523,"5. "]],[2523,2523],[2526,2526]]],[1555731281678,["28447@DESKTOP-BE7HQ26",[[1,2654,"4. \n"]],[2653,2653],[2657,2657]]],[1555731284335,["28447@DESKTOP-BE7HQ26",[[-1,2654,"4. "]],[2657,2657],[2654,2654]]],[1555731285132,["28447@DESKTOP-BE7HQ26",[[1,2654,"- "]],[2654,2654],[2656,2656]]],[1555731286168,["28447@DESKTOP-BE7HQ26",[[1,2654," "]],[2654,2654],[2655,2655]]],[1555731286830,["28447@DESKTOP-BE7HQ26",[[-1,2654," "]],[2655,2655],[2654,2654]]],[1555731287312,["28447@DESKTOP-BE7HQ26",[[1,2654,"  "]],[2654,2654],[2656,2656]]],[1555731288153,["28447@DESKTOP-BE7HQ26",[[1,2658," "]],[2657,2657],[2658,2658]]],[1555736909557,["28447@DESKTOP-BE7HQ26",[[1,2659,"Receive-base"]],[2659,2659],[2671,2671]]],[1555736935876,["28447@DESKTOP-BE7HQ26",[[-1,2656,"-"],[1,2657,"* "],[1,2666,"r"],[1,2671,"\n*   Direct"]],[2656,2671],[2684,2684]]],[1555736938557,["28447@DESKTOP-BE7HQ26",[[1,2674,"  "]],[2674,2674],[2676,2676]]],[1555736954914,["28447@DESKTOP-BE7HQ26",[[1,2673,"：实时读取缓存到内存中"]],[2673,2673],[2684,2684]]],[1555736961890,["28447@DESKTOP-BE7HQ26",[[1,2697,"：定时批量读取"]],[2697,2697],[2704,2704]]],[1555736963103,["28447@DESKTOP-BE7HQ26",[[1,2705,"  * \n"]],[2704,2704],[2709,2709]]],[1555736964470,["28447@DESKTOP-BE7HQ26",[[-1,2707,"* "]],[2709,2709],[2707,2707]]],[1555737040014,["28447@DESKTOP-BE7HQ26",[[1,2689,"\n  * "]],[2684,2684],[2689,2689]]],[1555737040917,["28447@DESKTOP-BE7HQ26",[[-1,2687,"* "]],[2689,2689],[2687,2687]]],[1555737041329,["28447@DESKTOP-BE7HQ26",[[1,2687,"Spark官方最先提供了基于Receiver的Kafka数据消费模式。不过这种方式是先把数据从kafka中读取出来，然后缓存在内存，再定时处理。如果这时候集群退出，而偏移量又没处理好的话，数据就丢掉了，存在程序失败丢失数据的可能，后在Spark 1.2时引入一个配置参数spark.streaming.receiver.writeAheadLog.enable以规避此风险。"]],[2687,2687],[2874,2874]]],[1555737045343,["28447@DESKTOP-BE7HQ26",[[1,2897,"* \n  "]],[2894,2894],[2899,2899]]],[1555737046086,["28447@DESKTOP-BE7HQ26",[[-1,2895,"  * "]],[2899,2899],[2896,2896]]],[1555737046574,["28447@DESKTOP-BE7HQ26",[[-1,2895,"\n"]],[2896,2896],[2895,2895]]],[1555737161031,["28447@DESKTOP-BE7HQ26",[[1,2877,"\n  "]],[2874,2874],[2877,2877]]],[1555737165187,["28447@DESKTOP-BE7HQ26",[[1,2877,"类操作：## KafkaUtils#createStream"]],[2877,2877],[2907,2907]]],[1555737167238,["28447@DESKTOP-BE7HQ26",[[-1,2881,"##"]],[2883,2883],[2881,2881]]],[1555737169991,["28447@DESKTOP-BE7HQ26",[[-1,2892,"#"]],[2893,2893],[2892,2892]]],[1555737174366,["28447@DESKTOP-BE7HQ26",[[1,2892,"。"]],[2892,2892],[2893,2893]]],[1555737175268,["28447@DESKTOP-BE7HQ26",[[-1,2892,"。"]],[2893,2893],[2892,2892]]],[1555737175720,["28447@DESKTOP-BE7HQ26",[[1,2892,"."]],[2892,2892],[2893,2893]]],[1555737179239,["28447@DESKTOP-BE7HQ26",[[-1,2877,"类"]],[2878,2878],[2877,2877]]],[1555737181064,["28447@DESKTOP-BE7HQ26",[[1,2879,"de"]],[2879,2879],[2881,2881]]],[1555737181701,["28447@DESKTOP-BE7HQ26",[[-1,2879,"de"]],[2881,2881],[2879,2879]]],[1555737183280,["28447@DESKTOP-BE7HQ26",[[1,2879,"的类"]],[2879,2879],[2881,2881]]],[1555737184888,["28447@DESKTOP-BE7HQ26",[[1,2929,"* \n  "]],[2926,2926],[2931,2931]]],[1555737186091,["28447@DESKTOP-BE7HQ26",[[-1,2929,"* "]],[2931,2931],[2929,2929]]],[1555737205109,["28447@DESKTOP-BE7HQ26",[[1,2929,"## KafkaUtils#createDirectStream"]],[2929,2929],[2961,2961]]],[1555737206789,["28447@DESKTOP-BE7HQ26",[[-1,2929,"##"]],[2931,2931],[2929,2929]]],[1555737210741,["28447@DESKTOP-BE7HQ26",[[1,2929,"操作的类："]],[2929,2929],[2934,2934]]],[1555737213879,["28447@DESKTOP-BE7HQ26",[[-1,2945,"#"]],[2946,2946],[2945,2945]]],[1555737214349,["28447@DESKTOP-BE7HQ26",[[1,2945,"."]],[2945,2945],[2946,2946]]],[1555737219325,["28447@DESKTOP-BE7HQ26",[[1,2968,"  \n"]],[2964,2964],[2967,2967]]],[1555740745605,["28447@DESKTOP-BE7HQ26",[[1,2971,"  \n"]],[2964,2964],[2967,2967]]],[1555740745747,["28447@DESKTOP-BE7HQ26",[[1,2967,"Direct方式采用Kafka简单的consumer api方式来读取数据，无需经由ZooKeeper，此种方式不再需要专门Receiver来持续不断读取数据。当batch任务触发时，由Executor读取数据，并参与到其他Executor的数据计算过程中去。driver来决定读取多少offsets，并将offsets交由checkpoints来维护。将触发下次batch任务，再由Executor读取Kafka数据并计算。从此过程我们可以发现Direct方式无需Receiver读取数据，而是需要计算时再读取数据，所以Direct方式的数据消费对内存的要求不高，只需要考虑批量计算所需要的内存即可；另外batch任务堆积时，也不会影响数据堆积。其具体读取方式如下图："]],[2967,2967],[3302,3302]]],[1555740752349,["28447@DESKTOP-BE7HQ26",[[1,3309,"  \n"]],[3302,3302],[3305,3305]]],[1555740919782,["28447@DESKTOP-BE7HQ26",[[1,3308,"Receive_base VS   Direct两种方式的优缺点：\n\nDirect方式具有以下方面的优势：\n\n1、简化并行(Simplified Parallelism)。不现需要创建以及union多输入源，Kafka topic的partition与RDD的partition一一对应\n\n2、高效(Efficiency)。Receiver-based保证数据零丢失(zero-data loss)需要配置spark.streaming.receiver.writeAheadLog.enable,此种方式需要保存两份数据，浪费存储空间也影响效率。而Direct方式则不存在这个问题。\n\n3、强一致语义(Exactly-once semantics)。High-level数据由Spark Streaming消费，但是Offsets则是由Zookeeper保存。通过参数配置，可以实现at-least once消费，此种情况有重复消费数据的可能。\n\n4、降低资源。Direct不需要Receivers，其申请的Executors全部参与到计算任务中；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。\n\n5、降低内存。Receiver-based的Receiver与其他Exectuor是异步的，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。\n\n6、鲁棒性更好。Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。Direct 则没有这种顾虑，其Driver在触发batch 计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。\n\nDirect方式的缺点：\n\n*   提高成本。Direct需要用户采用checkpoint或者第三方存储来维护offsets，而不像Receiver-based那样，通过ZooKeeper来维护Offsets，此提高了用户的开发成本。\n*   监控可视化。Receiver-based方式指定topic指定consumer的消费情况均能通过ZooKeeper来监控，而Direct则没有这种便利，如果做到监控并可视化，则需要投入人力开发。"]],[3308,3308],[4451,4451]]],[1555740924890,["28447@DESKTOP-BE7HQ26",[[-1,3306,"  Receive_base VS   Direct两种方式的优缺点："]],[3306,3341],[3306,3306]]],[1555740925741,["28447@DESKTOP-BE7HQ26",[[1,3306,"****"]],[3306,3306],[3308,3308]]],[1555740926091,["28447@DESKTOP-BE7HQ26",[[1,3308,"  Receive_base VS   Direct两种方式的优缺点："]],[3308,3308],[3343,3343]]],[1555740931824,["28447@DESKTOP-BE7HQ26",[[-1,3308,"  R"]],[3310,3310],[3308,3308]]],[1555740933146,["28447@DESKTOP-BE7HQ26",[[1,3308,"R"],[-1,3323," "],[1,3324," "]],[3308,3308],[3309,3309]]],[1555740944581,["28447@DESKTOP-BE7HQ26",[[1,4454,"* \n"]],[4453,4453],[4456,4456]]],[1555740945021,["28447@DESKTOP-BE7HQ26",[[-1,4454,"* "]],[4456,4456],[4455,4455]]],[1555740963832,["28447@DESKTOP-BE7HQ26",[[1,4455,"Receive-base优点：\n\n1、Kafka的high-level数据读取方式让用户可以专注于所读数据，而不用关注或维护consumer的offsets，这减少用户的工作量以及代码量而且相对比较简单。\n\nReceive-base的缺点：\n\n1、防数据丢失。做checkpoint操作以及配置spark.streaming.receiver.writeAheadLog.enable参数，配置spark.streaming.receiver.writeAheadLog.enable参数，每次处理之前需要将该batch内的日志备份到checkpoint目录中，这降低了数据处理效率，反过来又加重了Receiver端的压力；另外由于数据备份机制，会受到负载影响，负载一高就会出现延迟的风险，导致应用崩溃。\n\n2、单Receiver内存。由于receiver也是属于Executor的一部分，那么为了提高吞吐量，提高Receiver的内存。但是在每次batch计算中，参与计算的batch并不会使用到这么多的内存，导致资源严重浪费。\n\n3、在程序失败恢复时，有可能出现数据部分落地，但是程序失败，未更新offsets的情况，这导致数据重复消费。\n\n4、提高并行度，采用多个Receiver来保存Kafka的数据。Receiver读取数据是异步的，并不参与计算。如果开较高的并行度来平衡吞吐量很不划算。5、Receiver和计算的Executor的异步的，那么遇到网络等因素原因，导致计算出现延迟，计算队列一直在增加，而Receiver则在一直接收数据，这非常容易导致程序崩溃。\n\n6、采用MEMORY_AND_DISK_SER降低对内存的要求。但是在一定程度上影响计算的速度"]],[4455,4455],[5191,5191]]],[1555740968653,["28447@DESKTOP-BE7HQ26",[[1,5207,"5. \n"]],[5206,5206],[5210,5210]]],[1555740969203,["28447@DESKTOP-BE7HQ26",[[-1,5207,"5. "]],[5210,5210],[5208,5208]]],[1555740970167,["28447@DESKTOP-BE7HQ26",[[1,5209,"\n"]],[5208,5208],[5209,5209]]],[1555741009821,["28447@DESKTOP-BE7HQ26",[[1,5195,"\n"]],[5193,5193],[5194,5194]]],[1555741012802,["28447@DESKTOP-BE7HQ26",[[1,5194,"![Kafka结合Streaming的两种方式]($resource/Kafka%E7%BB%93%E5%90%88Streaming%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png)"]],[5194,5194],[5312,5312]]]],null,"28447@DESKTOP-BE7HQ26"],["52b271c5-ce44-4655-8592-6691ebbbe3e0",1555851782750,"# mianshi\n\n\n大数据面试    张浩\n\n**策略**\n\n1.  抛砖引玉\n\n2.  反客为主\n\n（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）\n\n用A4纸写把项目的部分写下来\n\n**项目介绍部分：**\n\n1.  架构设计（画图）\n\n2.  组件选择（调研+压测）\n\n3.  集群规模\n\n4.  高可靠的实现\n\n5.  压缩格式\n\n6.  文件格式\n\n7.  每秒、每分钟数据量   离线、实时的数据量\n\n8.  哪块高可靠没有做（ flume memory | spark yarn 调优）\n\n9.  集群调优（硬件、Linux、JVM、CDH、HDFS）\n\n开发内容：\n\n1.  Spark、Hive\n\n2.  存储\n\n3.  监控（运维）\n\n补充：\n\n1.  Hive、Spark调优\n\n2.  Bug怎么去解决\n\n3.  算法\n\n4.  机器学习\n\n5.  仓库\n\n6.  YARN怎么调优\n\n7.  CDH资源池\n\n**Java部分**\n\n1.  GC、JVM垃圾选择器参数\n\n2.  Java值传递与对象传递的区别\n\n3.  Java的多继承、多态\n\n\n4.  Java的sleep和wait的区别\n\n5.  HashMap和HashTable的区别\n\n6.  Java的多线程有哪几种形式\n\n7.  Java接口和抽象类的区别\n- 抽象类是捕捉子类的一般特性，抽象类是被用来创建继承层级里子类的模板；\n- 接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。\n\n| **参数** | **抽象类** | **接口** |\n| :-----:| :--------: | :-----: |\n| 默认的方法实现 | 它可以有默认的方法实现 | 接口完全是抽象的。它根本不存在方法的实现 |\n| 实现 | 子类使用**extends**关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。 | 子类使用关键字**implements**来实现接口。它需要提供接口中所有声明的方法的实现 |\n| 构造器 | 抽象类可以有构造器 | 接口不能有构造器 |\n| 与正常Java类的区别 | 除了你不能实例化抽象类之外，它和普通Java类没有任何区别 | 接口是完全不同的类型 |\n| 访问修饰符 | 抽象方法可以有**public**、**protected**和**default**这些修饰符 | 接口方法默认修饰符是**public**。你不可以使用其它修饰符。 |\n| main方法 | 抽象方法可以有main方法并且我们可以运行它 | 接口没有main方法，因此我们不能运行它。 |\n| 多继承 | 抽象方法可以继承一个类和实现多个接口 | 接口只可以继承一个或多个其它接口 |\n| 速度 | 它比接口速度要快 | 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。 |\n| 添加新方法 | 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 | 如果你往接口中添加方法，那么你必须改变实现该接口的类。 |\n什么时候使用抽象类和接口：\n*   如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。\n*   如果你想实现多重继承，那么你必须使用接口。由于**Java不支持多继承**，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。\n*   如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。\n\n**大数据部分：**\n\n1.  HDFS读写流程\n\n2.  YARN怎么调整Memory和CPU的资源\n\n3.  MR作业和Spark作业在YARN的流程 \n\n1.  Hive的分组排序\n\n2.  Hive的自定义函数\n\n3.  Hive的left join、left outer join和left semi join的主要区别\n\n1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)\n\n2.  Spark RDD的五大特性\n   - 1. A list of partitions\n   RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）\n   - 2. A function for computing each split\n   RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。\n   - 3. A list of dependencies on other RDDs\n    RDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。\n  - 4. Optionally,a Partitioner for Key-value RDDs\n  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面\n  - 5. Optionally, a list of preferred locations to compute each split on\n    **最优的位置**去计算，也就是**数据的本地性**。\n\n\n3.  Spark读取Kafka的两种方式，两者区别\n  *   Receiver-base：实时读取缓存到内存中\n  Spark官方最先提供了基于Receiver的Kafka数据消费模式。不过这种方式是先把数据从kafka中读取出来，然后缓存在内存，再定时处理。如果这时候集群退出，而偏移量又没处理好的话，数据就丢掉了，存在程序失败丢失数据的可能，后在Spark 1.2时引入一个配置参数spark.streaming.receiver.writeAheadLog.enable以规避此风险。\n  操作的类： KafkaUtils.createStream\n  *   Direct：定时批量读取\n  操作的类： KafkaUtils.createDirectStream\n  Direct方式采用Kafka简单的consumer api方式来读取数据，无需经由ZooKeeper，此种方式不再需要专门Receiver来持续不断读取数据。当batch任务触发时，由Executor读取数据，并参与到其他Executor的数据计算过程中去。driver来决定读取多少offsets，并将offsets交由checkpoints来维护。将触发下次batch任务，再由Executor读取Kafka数据并计算。从此过程我们可以发现Direct方式无需Receiver读取数据，而是需要计算时再读取数据，所以Direct方式的数据消费对内存的要求不高，只需要考虑批量计算所需要的内存即可；另外batch任务堆积时，也不会影响数据堆积。其具体读取方式如下图：\n  \n**Receive_base VS   Direct两种方式的优缺点：**\n\nDirect方式具有以下方面的优势：\n\n1、简化并行(Simplified Parallelism)。不现需要创建以及union多输入源，Kafka topic的partition与RDD的partition一一对应\n\n2、高效(Efficiency)。Receiver-based保证数据零丢失(zero-data loss)需要配置spark.streaming.receiver.writeAheadLog.enable,此种方式需要保存两份数据，浪费存储空间也影响效率。而Direct方式则不存在这个问题。\n\n3、强一致语义(Exactly-once semantics)。High-level数据由Spark Streaming消费，但是Offsets则是由Zookeeper保存。通过参数配置，可以实现at-least once消费，此种情况有重复消费数据的可能。\n\n4、降低资源。Direct不需要Receivers，其申请的Executors全部参与到计算任务中；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。\n\n5、降低内存。Receiver-based的Receiver与其他Exectuor是异步的，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。\n\n6、鲁棒性更好。Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。Direct 则没有这种顾虑，其Driver在触发batch 计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。\n\nDirect方式的缺点：\n\n*   提高成本。Direct需要用户采用checkpoint或者第三方存储来维护offsets，而不像Receiver-based那样，通过ZooKeeper来维护Offsets，此提高了用户的开发成本。\n*   监控可视化。Receiver-based方式指定topic指定consumer的消费情况均能通过ZooKeeper来监控，而Direct则没有这种便利，如果做到监控并可视化，则需要投入人力开发。\n\nReceive-base优点：\n\n1、Kafka的high-level数据读取方式让用户可以专注于所读数据，而不用关注或维护consumer的offsets，这减少用户的工作量以及代码量而且相对比较简单。\n\nReceive-base的缺点：\n\n1、防数据丢失。做checkpoint操作以及配置spark.streaming.receiver.writeAheadLog.enable参数，配置spark.streaming.receiver.writeAheadLog.enable参数，每次处理之前需要将该batch内的日志备份到checkpoint目录中，这降低了数据处理效率，反过来又加重了Receiver端的压力；另外由于数据备份机制，会受到负载影响，负载一高就会出现延迟的风险，导致应用崩溃。\n\n2、单Receiver内存。由于receiver也是属于Executor的一部分，那么为了提高吞吐量，提高Receiver的内存。但是在每次batch计算中，参与计算的batch并不会使用到这么多的内存，导致资源严重浪费。\n\n3、在程序失败恢复时，有可能出现数据部分落地，但是程序失败，未更新offsets的情况，这导致数据重复消费。\n\n4、提高并行度，采用多个Receiver来保存Kafka的数据。Receiver读取数据是异步的，并不参与计算。如果开较高的并行度来平衡吞吐量很不划算。5、Receiver和计算的Executor的异步的，那么遇到网络等因素原因，导致计算出现延迟，计算队列一直在增加，而Receiver则在一直接收数据，这非常容易导致程序崩溃。\n\n6、采用MEMORY_AND_DISK_SER降低对内存的要求。但是在一定程度上影响计算的速度  \n![Kafka结合Streaming的两种方式]($resource/Kafka%E7%BB%93%E5%90%88Streaming%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png)\n\n4.  Spark调优\n\n\n\n5.  数据倾斜\n\n6.  压缩格式\n\n7.  文件格式\n\n     **大数据项目部分**\n\n1.  集群的规模\n\n2.  每秒、每分钟、每小时、每天的吞吐量\n\n3.  一个作业多大？多少资源？多久跑完\n\n4.  如何设置作业的资源\n\n5.  高可靠\n\n6.  生产的优化\n\n     **其他**\n\n1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题\n\n2.  进去公司的时候工资一定要要到位\n\n3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题\n\n4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”\n",[[1555851729540,["28447@DESKTOP-BE7HQ26",[[1,4977,"k"]],[4977,4977],[4978,4978]]],[1555851730529,["28447@DESKTOP-BE7HQ26",[[-1,4977,"k"]],[4978,4978],[4977,4977]]],[1555851734262,["28447@DESKTOP-BE7HQ26",[[-1,5001,"Kafka"]],[5001,5006],[5001,5001]]],[1555851756827,["28447@DESKTOP-BE7HQ26",[[1,1560,"# "]],[1560,1560],[1562,1562]]],[1555851761860,["28447@DESKTOP-BE7HQ26",[[-1,1569,"："]],[1570,1570],[1569,1569]]],[1555851765732,["28447@DESKTOP-BE7HQ26",[[-1,1562,"**"]],[1564,1564],[1562,1562]]],[1555851766558,["28447@DESKTOP-BE7HQ26",[[-1,1567,"**"]],[1569,1569],[1567,1567]]],[1555851773045,["28447@DESKTOP-BE7HQ26",[[1,1967,"## "]],[1967,1967],[1970,1970]]],[1555851781757,["28447@DESKTOP-BE7HQ26",[[1,2627,"## "]],[2627,2627],[2630,2630]]],[1555851960445,["28447@DESKTOP-BE7HQ26",[[1,5311,"## "]],[5311,5311],[5314,5314]]]],null,"28447@DESKTOP-BE7HQ26"],["1a3512bd-c25a-465c-b7b7-28e40b0948a3",1555854615023,"# mianshi\n\n\n大数据面试    张浩\n\n**策略**\n\n1.  抛砖引玉\n\n2.  反客为主\n\n（自己主动说，不要等着被面试官问，说完一段内容，可以停顿一下，然后接着说）\n\n用A4纸写把项目的部分写下来\n\n**项目介绍部分：**\n\n1.  架构设计（画图）\n\n2.  组件选择（调研+压测）\n\n3.  集群规模\n\n4.  高可靠的实现\n\n5.  压缩格式\n\n6.  文件格式\n\n7.  每秒、每分钟数据量   离线、实时的数据量\n\n8.  哪块高可靠没有做（ flume memory | spark yarn 调优）\n\n9.  集群调优（硬件、Linux、JVM、CDH、HDFS）\n\n开发内容：\n\n1.  Spark、Hive\n\n2.  存储\n\n3.  监控（运维）\n\n补充：\n\n1.  Hive、Spark调优\n\n2.  Bug怎么去解决\n\n3.  算法\n\n4.  机器学习\n\n5.  仓库\n\n6.  YARN怎么调优\n\n7.  CDH资源池\n\n**Java部分**\n\n1.  GC、JVM垃圾选择器参数\n\n2.  Java值传递与对象传递的区别\n\n3.  Java的多继承、多态\n\n\n4.  Java的sleep和wait的区别\n\n5.  HashMap和HashTable的区别\n\n6.  Java的多线程有哪几种形式\n\n7.  Java接口和抽象类的区别\n- 抽象类是捕捉子类的一般特性，抽象类是被用来创建继承层级里子类的模板；\n- 接口是抽象方法的集合。如果一个类实现了某个接口，那么它就继承了这个接口的抽象方法。这就像契约模式，如果实现了这个接口，那么就必须确保使用这些方法。\n\n| **参数** | **抽象类** | **接口** |\n| :-----:| :--------: | :-----: |\n| 默认的方法实现 | 它可以有默认的方法实现 | 接口完全是抽象的。它根本不存在方法的实现 |\n| 实现 | 子类使用**extends**关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。 | 子类使用关键字**implements**来实现接口。它需要提供接口中所有声明的方法的实现 |\n| 构造器 | 抽象类可以有构造器 | 接口不能有构造器 |\n| 与正常Java类的区别 | 除了你不能实例化抽象类之外，它和普通Java类没有任何区别 | 接口是完全不同的类型 |\n| 访问修饰符 | 抽象方法可以有**public**、**protected**和**default**这些修饰符 | 接口方法默认修饰符是**public**。你不可以使用其它修饰符。 |\n| main方法 | 抽象方法可以有main方法并且我们可以运行它 | 接口没有main方法，因此我们不能运行它。 |\n| 多继承 | 抽象方法可以继承一个类和实现多个接口 | 接口只可以继承一个或多个其它接口 |\n| 速度 | 它比接口速度要快 | 接口是稍微有点慢的，因为它需要时间去寻找在类中实现的方法。 |\n| 添加新方法 | 如果你往抽象类中添加新的方法，你可以给它提供默认的实现。因此你不需要改变你现在的代码。 | 如果你往接口中添加方法，那么你必须改变实现该接口的类。 |\n什么时候使用抽象类和接口：\n*   如果你拥有一些方法并且想让它们中的一些有默认实现，那么使用抽象类吧。\n*   如果你想实现多重继承，那么你必须使用接口。由于**Java不支持多继承**，子类不能够继承多个类，但可以实现多个接口。因此你就可以使用接口来解决它。\n*   如果基本功能在不断改变，那么就需要使用抽象类。如果不断改变基本功能并且使用接口，那么就需要改变所有实现了该接口的类。\n\n# 大数据部分\n\n1.  HDFS读写流程\n\n2.  YARN怎么调整Memory和CPU的资源\n\n3.  MR作业和Spark作业在YARN的流程 \n\n1.  Hive的分组排序\n\n2.  Hive的自定义函数\n\n3.  Hive的left join、left outer join和left semi join的主要区别\n\n1.  有没有阅读过Spark的源码（一定回答阅读过，可以在github上看一下RDD的源码 ） [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/rdd/RDD.scala)\n\n## 2.  Spark RDD的五大特性\n   - 1. A list of partitions\n   RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）\n   - 2. A function for computing each split\n   RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。\n   - 3. A list of dependencies on other RDDs\n    RDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。\n  - 4. Optionally,a Partitioner for Key-value RDDs\n  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面\n  - 5. Optionally, a list of preferred locations to compute each split on\n    **最优的位置**去计算，也就是**数据的本地性**。\n\n\n## 3.  Spark读取Kafka的两种方式，两者区别\n  *   Receiver-base：实时读取缓存到内存中\n  Spark官方最先提供了基于Receiver的Kafka数据消费模式。不过这种方式是先把数据从kafka中读取出来，然后缓存在内存，再定时处理。如果这时候集群退出，而偏移量又没处理好的话，数据就丢掉了，存在程序失败丢失数据的可能，后在Spark 1.2时引入一个配置参数spark.streaming.receiver.writeAheadLog.enable以规避此风险。\n  操作的类： KafkaUtils.createStream\n  *   Direct：定时批量读取\n  操作的类： KafkaUtils.createDirectStream\n  Direct方式采用Kafka简单的consumer api方式来读取数据，无需经由ZooKeeper，此种方式不再需要专门Receiver来持续不断读取数据。当batch任务触发时，由Executor读取数据，并参与到其他Executor的数据计算过程中去。driver来决定读取多少offsets，并将offsets交由checkpoints来维护。将触发下次batch任务，再由Executor读取Kafka数据并计算。从此过程我们可以发现Direct方式无需Receiver读取数据，而是需要计算时再读取数据，所以Direct方式的数据消费对内存的要求不高，只需要考虑批量计算所需要的内存即可；另外batch任务堆积时，也不会影响数据堆积。其具体读取方式如下图：\n  \n**Receive_base VS   Direct两种方式的优缺点：**\n\nDirect方式具有以下方面的优势：\n\n1、简化并行(Simplified Parallelism)。不现需要创建以及union多输入源，Kafka topic的partition与RDD的partition一一对应\n\n2、高效(Efficiency)。Receiver-based保证数据零丢失(zero-data loss)需要配置spark.streaming.receiver.writeAheadLog.enable,此种方式需要保存两份数据，浪费存储空间也影响效率。而Direct方式则不存在这个问题。\n\n3、强一致语义(Exactly-once semantics)。High-level数据由Spark Streaming消费，但是Offsets则是由Zookeeper保存。通过参数配置，可以实现at-least once消费，此种情况有重复消费数据的可能。\n\n4、降低资源。Direct不需要Receivers，其申请的Executors全部参与到计算任务中；而Receiver-based则需要专门的Receivers来读取Kafka数据且不参与计算。因此相同的资源申请，Direct 能够支持更大的业务。\n\n5、降低内存。Receiver-based的Receiver与其他Exectuor是异步的，并持续不断接收数据，对于小业务量的场景还好，如果遇到大业务量时，需要提高Receiver的内存，但是参与计算的Executor并无需那么多的内存。而Direct 因为没有Receiver，而是在计算时读取数据，然后直接计算，所以对内存的要求很低。实际应用中我们可以把原先的10G降至现在的2-4G左右。\n\n6、鲁棒性更好。Receiver-based方法需要Receivers来异步持续不断的读取数据，因此遇到网络、存储负载等因素，导致实时任务出现堆积，但Receivers却还在持续读取数据，此种情况很容易导致计算崩溃。Direct 则没有这种顾虑，其Driver在触发batch 计算任务时，才会读取数据并计算。队列出现堆积并不会引起程序的失败。\n\nDirect方式的缺点：\n\n*   提高成本。Direct需要用户采用checkpoint或者第三方存储来维护offsets，而不像Receiver-based那样，通过ZooKeeper来维护Offsets，此提高了用户的开发成本。\n*   监控可视化。Receiver-based方式指定topic指定consumer的消费情况均能通过ZooKeeper来监控，而Direct则没有这种便利，如果做到监控并可视化，则需要投入人力开发。\n\nReceive-base优点：\n\n1、Kafka的high-level数据读取方式让用户可以专注于所读数据，而不用关注或维护consumer的offsets，这减少用户的工作量以及代码量而且相对比较简单。\n\nReceive-base的缺点：\n\n1、防数据丢失。做checkpoint操作以及配置spark.streaming.receiver.writeAheadLog.enable参数，配置spark.streaming.receiver.writeAheadLog.enable参数，每次处理之前需要将该batch内的日志备份到checkpoint目录中，这降低了数据处理效率，反过来又加重了Receiver端的压力；另外由于数据备份机制，会受到负载影响，负载一高就会出现延迟的风险，导致应用崩溃。\n\n2、单Receiver内存。由于receiver也是属于Executor的一部分，那么为了提高吞吐量，提高Receiver的内存。但是在每次batch计算中，参与计算的batch并不会使用到这么多的内存，导致资源严重浪费。\n\n3、在程序失败恢复时，有可能出现数据部分落地，但是程序失败，未更新offsets的情况，这导致数据重复消费。\n\n4、提高并行度，采用多个Receiver来保存的数据。Receiver读取数据是异步的，并不参与计算。如果开较高的并行度来平衡吞吐量很不划算。5、Receiver和计算的Executor的异步的，那么遇到网络等因素原因，导致计算出现延迟，计算队列一直在增加，而Receiver则在一直接收数据，这非常容易导致程序崩溃。\n\n6、采用MEMORY_AND_DISK_SER降低对内存的要求。但是在一定程度上影响计算的速度  \n![Kafka结合Streaming的两种方式]($resource/Kafka%E7%BB%93%E5%90%88Streaming%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png)\n\n## 4.  Spark调优\n\n\n\n5.  数据倾斜\n\n6.  压缩格式\n\n7.  文件格式\n\n     **大数据项目部分**\n\n1.  集群的规模\n\n2.  每秒、每分钟、每小时、每天的吞吐量\n\n3.  一个作业多大？多少资源？多久跑完\n\n4.  如何设置作业的资源\n\n5.  高可靠\n\n6.  生产的优化\n\n     **其他**\n\n1.  IQ测试题，如果安排在会议室，没有摄像头，可百度搜索这些题\n\n2.  进去公司的时候工资一定要要到位\n\n3.  你还有什么问题吗？ 如果是技术问你，可以问团队构成、方向、技术、分析的东西；如果是HR问你，可以问晋升机制、新人培养问题\n\n4.  你怎么看待加班？可以回答：“如果是工作需要，我会义无反顾的加班，同时我也会提高自己的工作效率，避免不必要的加班”\n",[[1555854573940,["28447@DESKTOP-BE7HQ26",[[-1,3293,"。其具体读取方式如下图："]],[3294,3305],[3293,3293]]],[1555854575534,["28447@DESKTOP-BE7HQ26",[[1,3293,"."]],[3293,3293],[3294,3294]]]],null,"28447@DESKTOP-BE7HQ26"]]}