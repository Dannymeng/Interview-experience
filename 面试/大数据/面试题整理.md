# 面试题整理

<!-- GFM-TOC -->
* [一、Spark篇](#Spark篇)
    * [Spark任务提交流程](#Spark任务提交流程)
    * [Spark RDD的五大特性](#RDD的五大特性)
    * [Transform和Action算子](#Transform和Action算子) 
    * [Spark中有了RDD，为什么还要有Dataframe和DataSet](#Spark中有了RDD为什么还要有Dataframe和DataSet)
    * [Spark shuffle过程](#SparkShuffle过程)
    * [Spark读取Kafka的两种方式，两者区别](#Spark读取Kafka的两种方式及两者区别)
    * [Spark性能调优](#Spark性能调优)
 * [二、Hadoop篇](#Hadoop篇)
     * [Yarn的认识](#Yarn的认识)
 * [三、Zookeeper篇](#Zookeeper篇)
   * [Zookeeper简单介绍](#Zookeeper简单介绍)
   * [为什么zookeeper集群的节点数是奇数个](#为什么zookeeper集群的节点数是奇数个)
 * [四、Hive篇](#Hive篇) 
   * [Hive是什么](#Hive是什么)
<!-- GFM-TOC -->

## Spark篇

### Spark运行流程
![](https://img-blog.csdn.net/20180816192305504?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdmVjaGVuZG9uZ3hpbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### Spark任务提交流程
- 1.SparkContext提交作业
- 2.DAGScheduler拆分stage
- 3.生成作业
- 4.提交任务集
- 5.TaskScheduler提交任务
- 6.执行任务
- 7.跟踪任务


![Spark任务提交流程图.jpg](https://github.com/Dannymeng/bigdata_note/blob/master/picture/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%80%BB%E4%BD%93%E8%AF%A0%E9%87%8A.jpg?raw=true)


### RDD的五大特性
   - 1. A list of partitions
   RDD是一个由多个partition（某个节点里的某一片连续的数据）组成的list；将数据加载为RDD时，一般会遵循数据的本地性（一般一个hdfs里的block会加载为一个partition）
   - 2. A function for computing each split
   RDD的每个partition上面都会有function，也就是函数应用，其作用是实现RDD之间partition的转换。
   - 3. A list of dependencies on other RDDs
    RDD会记录它的依赖 ，为了容错（重算，cache，checkpoint），也就是说在内存中的RDD操作时出错或丢失会进行重算。
  - 4. Optionally,a Partitioner for Key-value RDDs
  可选项，如果RDD里面存的数据是key-value形式，则可以传递一个自定义的Partitioner进行重新分区，例如这里自定义的Partitioner是基于key进行分区，那则会将不同RDD里面的相同key的数据放到同一个partition里面
  - 5. Optionally, a list of preferred locations to compute each split on
    **最优的位置**去计算，也就是**数据的本地性**。

### transform和action算子
Transformation不会立即执行，只是记录这些操作 
action会执行前边的Transformation所有操作

**transform算子得到新的RDD**
常见transform算子：map（针对每个元素）、mapPartitions（针对partition）、filter、**flatMap**、union、**distinct**、**groupByKey**、**reduceByKey**、sortByKey、join

**action得到值**
常见action算子：reduce、count、collect、saveAsTextFile、countByKey、foreach

[常见算子](https://my.oschina.net/134596/blog/3037972)
[算子操作示例](https://blog.csdn.net/huozi07/article/details/50133259)

### Spark中有了RDD为什么还要有Dataframe和DataSet
SparkSQL不支持RDD,支持DataFrame和dataSet


### SparkShuffle过程
shuffle发生在两个stage之间，
shuffle中的概念：shuffleMapTask 和 ResultTask
两种方式：**HashShuffleManager**和 **SortShuffleManager**
HashShuffleManager分为改进之前和改进之后，改经前文件数task1*task2
改进之后文件数core数*task2
SortShuffleManager文件数：上游stage的task数量

[shuffle参考文章](https://blog.csdn.net/quitozang/article/details/80904040)


### Spark读取Kafka的两种方式及两者区别
- 1.  Receiver-base：实时读取缓存到内存中
先把数据从kafka中读取出来，然后缓存在内存，再定时处理。如果这时候集群退出，而偏移量又没处理好的话，数据就丢掉了，存在程序失败丢失数据的可能，后在Spark 1.2时引入一个配置参数spark.streaming.receiver.writeAheadLog.enable以规避此风险。
操作的类： **KafkaUtils.createStream**
zookeeper维护offset
- 2.  Direct：定时批量读取
Direct方式无需Receiver读取数据，而是需要计算时再读取数据，所以Direct方式的数据消费对内存的要求不高，只需要考虑批量计算所需要的内存即可；另外batch任务堆积时，也不会影响数据堆积。
  操作的类： **KafkaUtils.createDirectStream**
  程序自己维护offset
  

![Kafka连接Spark两种方式.png](https://github.com/Dannymeng/bigdata_note/blob/master/picture/Kafka%E7%BB%93%E5%90%88Streaming%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.png?raw=true)

### Spark性能调优
1. **小分区合并的问题**
由于程序中过度使用filter算子或者使用不当，都会造成大量的小分区出现。

**带来的问题就是：任务处理的数据量很小，反复地切换任务所消耗的资源反而会带来很大的系统开销。**

**解决方案：使用重分区函数coalesce进行数据紧缩、减少分区数并设置shuffle=true保证任务是并行计算的**（或者使用**repartition**重分区，其底层使用的是coalesce并设置Shuffle=true）

2. **数据倾斜问题**
典型的场景是：大量的数据被分配到小部分节点计算，而其他大部分节点却只计算小部分数据。





[Spark性能调优](https://www.cnblogs.com/jchubby/p/5449373.html)


## Hadoop篇

### MapReduce原理
- 1、读取文件系统，转化为<K,V>，K为偏移量
- 2、根据map处理业务，得到另一个<K,V>
- 3、对<K,V>分组
- 4、以组为单位归约
- 5、迭代，将最终产生的<K,V>保存到输出中

### Yarn的认识
Yarn是hadoop2.X之后出现的Hadoop 资源管理器，它是一个**资源管理系统和调度平台**。

YARN 是一个资源管理、任务调度的框架，主要包含三大模块：ResourceManager（RM）、
NodeManager（NM）、ApplicationMaster（AM）。
- ResourceManager 负责所有资源的监控、分配和管理；
- ApplicationMaster 负责每一个具体应用程序的调度和协调；
- NodeManager 负责每一个节点的维护。
对于所有的 applications，RM 拥有绝对的控制权和对资源的分配权。而每个 AM 则会和
RM 协商资源，同时和 NodeManager 通信来执行和监控 task。

![Yarn.png](https://github.com/Dannymeng/bigdata_note/blob/master/picture/Yarn%E6%9E%B6%E6%9E%84%E5%9B%BE.png?raw=true)

[参考文章](https://blog.csdn.net/qq_33624952/article/details/79341034)

## Zookeeper篇

### Zookeeper简单介绍
ZooKeeper是一个开放源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态.

分布式应用程序可以基于Zookeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。

### 为什么zookeeper集群的节点数是奇数个
首先介绍zookeeper选举的规则：leader选举，要求**可用节点数量 > 总节点数量/2**
设置奇数个的目的：
**1、防止由脑裂造成的集群不可用**
**2、在容错能力相同的情况下，奇数台更节省资源。**

[zookeeper为什么是奇数个集群 参考文章](https://blog.csdn.net/u010476994/article/details/79806041)

## Hive篇

### Hive是什么
 Hive 是基于 Hadoop 构建的一套数据仓库分析系统，用来进行数据提取转化加载（ETL）（利用mapreduce挖掘hdfs上的数据）
 
[Hive参考文章](https://blog.csdn.net/francis_lzz/article/details/77720827)



