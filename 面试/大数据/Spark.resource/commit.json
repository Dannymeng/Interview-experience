{"compress":true,"commitItems":[["8fb3e175-e3a1-4c6f-b020-0854261cbc82",1555308060999,"",[[1555308004323,["28447@DESKTOP-BE7HQ26",[[1,0,"# Spark\n\n\n\n"]],[0,0],[10,10]]],[1555309006358,["28447@DESKTOP-BE7HQ26",[[1,10,"===="]],[10,10],[12,12]]],[1555309008774,["28447@DESKTOP-BE7HQ26",[[-1,10,"===="]],[10,14],[10,10]]]],null,"28447@DESKTOP-BE7HQ26"],["683cf35a-892b-4a8f-9292-f4bf9f169bb1",1555476663781,"# Spark\n\n\n\n",[[1555476621090,["28447@DESKTOP-BE7HQ26",[[1,11,"\n"]],[7,7],[8,8]]],[1555476621132,["28447@DESKTOP-BE7HQ26",[[1,12,"\n"]],[8,8],[9,9]]],[1555481129610,["28447@DESKTOP-BE7HQ26",[[1,11,"1.spark优化?\n架构参数优化：shuffle，内存管理，推测执行，数据本地化：HDFS的DataNode和Spark Worker共享一台机器\n代码层面：并行度--调整finalRDD partition；缓存机制的选择--CPU使用和内存使用的权衡：checkpoint；算子的使用和选择-groupbykey，map vs mappartitions等，使用广播变量，累加器等； 序列化：压缩，存储格式的选择\n数据倾斜：重写partition规则，抽样看数据的分布，结合具体的业务\n架构的选择：统一使用yarn结合hadoop，还是使用自己的standalone计算框架"]],[11,11],[301,301]]],[1555481135431,["28447@DESKTOP-BE7HQ26",[[1,11,"## "]],[11,11],[14,14]]],[1555481139163,["28447@DESKTOP-BE7HQ26",[[1,306,"\n"]],[304,304],[305,305]]],[1555481139354,["28447@DESKTOP-BE7HQ26",[[1,307,"\n"]],[305,305],[306,306]]],[1555481143414,["28447@DESKTOP-BE7HQ26",[[1,306,"## 。 "]],[306,306],[311,311]]],[1555481144097,["28447@DESKTOP-BE7HQ26",[[-1,309,"。 "]],[311,311],[309,309]]],[1555481145748,["28447@DESKTOP-BE7HQ26",[[1,309,"2. "]],[309,309],[312,312]]],[1555481270521,["28447@DESKTOP-BE7HQ26",[[1,314,"\n"]],[312,312],[313,313]]],[1555481270903,["28447@DESKTOP-BE7HQ26",[[1,313,"2.spark源码-DAG-Task--任务调度部分？\nspark是粗粒度的资源申请，任务调度：sparkContext-DAGSheduler切分stage，TaskSheduler发送任务到申请好的Executor中的线程池执行\n\n3.submit相关配置？一般指定多大的资源？\nsubmit --master/yarn --class --deploy model clster/client\nExecutor cores 默认一个Executor 1 core，lg内存，1G，2--3个task\n\n4.写完spark程序如何知道多少个task？（即资源如何调配的）\n看你的并行度的设置，block的数量，web UI"]],[313,313],[626,626]]],[1555481273065,["28447@DESKTOP-BE7HQ26",[[-1,313,"2."]],[315,315],[313,313]]],[1555481273362,["28447@DESKTOP-BE7HQ26",[[-1,312,"\n"]],[313,313],[312,312]]],[1555481279569,["28447@DESKTOP-BE7HQ26",[[1,428,"## "]],[428,428],[431,431]]],[1555481281874,["28447@DESKTOP-BE7HQ26",[[1,567,"## "]],[567,567],[570,570]]],[1555481283633,["28447@DESKTOP-BE7HQ26",[[1,631,"\n"]],[629,629],[630,630]]],[1555481283816,["28447@DESKTOP-BE7HQ26",[[1,632,"\n"]],[630,630],[631,631]]],[1555481293823,["28447@DESKTOP-BE7HQ26",[[1,631,"5.spark和mr性能是不是差别很多？\n一般来说Spark比Hadoop快：\n原因：\na.MR有大量的磁盘io,溢写等，Spark则可以基于内存缓存机制计算\nb.MR和Spark的资源申请的方式：粗粒度和细粒度的区别\nc.DAG计算引擎中的pipeline计算模型，MR就是MapReduce模型\nd.算子的丰富程度\n使用场景：大于pb级别的数据量一般选择MR\n生态的区别：Spark一站式的大数据处理平台，Hadoop还需要和其他的整合，升级，版本兼容等一堆问题，CDH版本如果需要更多的功能需要考虑成本的问题"]],[631,631],[888,888]]],[1555481297013,["28447@DESKTOP-BE7HQ26",[[1,631,"## "]],[631,631],[634,634]]],[1555481301225,["28447@DESKTOP-BE7HQ26",[[1,893,"\n"]],[892,892],[893,893]]],[1555481608206,["28447@DESKTOP-BE7HQ26",[[1,893,"6.spark任务yarn执行流程(client)?\n\n7.spark运行在Yarn上流程（cluster）?\n使用场景的区别：基于yarn的好处，兼容hadoop，一套计算框架，能好的维护\n\n8.spark调优？\n\n9.shuffle主要介绍下？\nshuffle发生？---shuffle的过程---shuffle实现的选择---shuffle的优化\n\n10.宽窄依赖？\n看父RDD和子RR的关系，除了父RDD和子RDD一对多外，其他的都是窄依赖\n\n11.shuffle怎么落地的？\nshuffle的实现类型：hash Shuffle还是sortShuffle？Shuffle数据落地？\n\n12.Spark RDD 是什么?\n弹性分布式数据集---源码的五大特性-----RDD的计算模型：pipeline计算模型\n\n13.Spark算子?\nmap，flatmap，filter，foreach，first，take(n),join,cogroup,reducebykey,sortBy,distinct,mapPartition等等\n\n14.spark 优势？\n一栈式大数据处理平台,灵活的编程模型,相比MR速度快\n\n15.spark on yarn 和mapreduce中yarn有什么区别？\n没什么区别，yarn就是一个资源管理框架\n\n16.spark原理？\npipeline计算模型+任务调度和资源调度\n\n17.spark运行的job在哪里可以看到？\nDriver进程所在的节点；web UI\n\n18.如何监测集群中cpu，内存的使用情况，比如说：有一个spark特别占资源，特别慢，怎么排查这种情况?\nspark WEB UI；集群监控工具，找到taskid\n\n20.rdd的处理过程是什么，不要说概念?\n画切分Stage，pipeline的计算模型的图\n\n21.spark的工作流程？\nSpark的资源调度和任务调度+pipeline的计算模型\n\n22.SparkSQL和Spark架构，运行流程图，Spark运行的两种方式。常用的Spark函数有哪些？\nspark架构图+运行流程图(资源的调度+任务调度)+Spark client和SparkCluster+transformation算子+action算子+持久化操作算子\n\n23.Spark了解多少？\nspark生态-架构-运行模式+任务调度和资源调度\n\n24：GroupByKey的作用？\n根据key分组\n\nSpark Sql的面试题：\n\n1.sparkSQL介绍下（RDD、DataFrame）\n\n关于Spark Streaming的面试题：\n\n2.sparkStreaming怎么跟kafka对接的,数据拉取到哪里？\n\n3.日流量10G没必要sparkstreaming？\n\n4.spark streaming 例子。问维护做过没？说sparkStreaming的维护成本很高。 我告诉他是的，比如说可能会丢数据，wal会慢。这一块儿不是我维护。没细问。\n\n5.spark streming调优?\n\n6.sparkstreaming原理？\n\n7.spark Streaming介绍下？和Storm比较？\n\n8.spark Streaming某一个task挂了，怎么解决的?\n\n9.spark streaming?spark的相关算法，比如推荐系统需要什么算法?\n\n10.park streaming工作流程？\n\n11.sparkstreanming没有问题，但无法计算，怎么排查问题?\n\n12.storm和spark streaming的区别？"]],[893,893],[2404,2404]]],[1555481611351,["28447@DESKTOP-BE7HQ26",[[1,893,"## "]],[893,893],[896,896]]],[1555481614677,["28447@DESKTOP-BE7HQ26",[[1,924,"## "]],[924,924],[927,927]]],[1555481617062,["28447@DESKTOP-BE7HQ26",[[1,996,"## "]],[996,996],[999,999]]],[1555481620086,["28447@DESKTOP-BE7HQ26",[[1,1011,"## "]],[1011,1011],[1014,1014]]],[1555481622381,["28447@DESKTOP-BE7HQ26",[[1,1083,"## "]],[1083,1083],[1086,1086]]],[1555481624690,["28447@DESKTOP-BE7HQ26",[[1,1134,"## "]],[1134,1134],[1137,1137]]],[1555481627430,["28447@DESKTOP-BE7HQ26",[[1,1207,"## "]],[1207,1207],[1210,1210]]],[1555481630190,["28447@DESKTOP-BE7HQ26",[[1,1274,"## "]],[1274,1274],[1277,1277]]],[1555481632671,["28447@DESKTOP-BE7HQ26",[[1,1387,"## "]],[1387,1387],[1390,1390]]],[1555481634399,["28447@DESKTOP-BE7HQ26",[[1,1431,"## "]],[1431,1431],[1434,1434]]],[1555481636670,["28447@DESKTOP-BE7HQ26",[[1,1495,"## "]],[1495,1495],[1498,1498]]],[1555481638169,["28447@DESKTOP-BE7HQ26",[[1,1534,"## "]],[1534,1534],[1537,1537]]],[1555481639782,["28447@DESKTOP-BE7HQ26",[[1,1582,"## "]],[1582,1582],[1585,1585]]],[1555481642422,["28447@DESKTOP-BE7HQ26",[[1,1669,"## "]],[1669,1669],[1672,1672]]],[1555481644734,["28447@DESKTOP-BE7HQ26",[[1,1720,"## "]],[1720,1720],[1723,1723]]],[1555481646294,["28447@DESKTOP-BE7HQ26",[[1,1769,"## "]],[1769,1769],[1772,1772]]],[1555481648263,["28447@DESKTOP-BE7HQ26",[[1,1914,"## "]],[1914,1914],[1917,1917]]],[1555481650193,["28447@DESKTOP-BE7HQ26",[[1,1958,"## "]],[1958,1958],[1961,1961]]],[1555481651599,["28447@DESKTOP-BE7HQ26",[[1,1988,"## "]],[1988,1988],[1991,1991]]],[1555481653902,["28447@DESKTOP-BE7HQ26",[[1,2007,"## "]],[2007,2007],[2010,2010]]],[1555481658175,["28447@DESKTOP-BE7HQ26",[[1,2064,"### "]],[2064,2064],[2068,2068]]],[1555481659824,["28447@DESKTOP-BE7HQ26",[[-1,2066,"# "]],[2068,2068],[2066,2066]]],[1555481660031,["28447@DESKTOP-BE7HQ26",[[1,2066," "]],[2066,2066],[2067,2067]]],[1555481662511,["28447@DESKTOP-BE7HQ26",[[1,2105,"## "]],[2105,2105],[2108,2108]]],[1555481666795,["28447@DESKTOP-BE7HQ26",[[1,2136,"## "]],[2136,2136],[2139,2139]]],[1555481669046,["28447@DESKTOP-BE7HQ26",[[1,2230,"## "]],[2230,2230],[2233,2233]]],[1555481671294,["28447@DESKTOP-BE7HQ26",[[1,2254,"## "]],[2254,2254],[2257,2257]]],[1555481672599,["28447@DESKTOP-BE7HQ26",[[1,2278,"## "]],[2278,2278],[2281,2281]]],[1555481674350,["28447@DESKTOP-BE7HQ26",[[1,2313,"## "]],[2313,2313],[2316,2316]]],[1555481676248,["28447@DESKTOP-BE7HQ26",[[1,2351,"## "]],[2351,2351],[2354,2354]]],[1555481678006,["28447@DESKTOP-BE7HQ26",[[1,2398,"## "]],[2398,2398],[2401,2401]]],[1555481679746,["28447@DESKTOP-BE7HQ26",[[1,2425,"## "]],[2425,2425],[2428,2428]]],[1555481681577,["28447@DESKTOP-BE7HQ26",[[1,2466,"## "]],[2466,2466],[2469,2469]]],[1555481704014,["28447@DESKTOP-BE7HQ26",[[1,924,"\n"]],[923,923],[924,924]]],[1555481704216,["28447@DESKTOP-BE7HQ26",[[1,925,"\n"]],[924,924],[925,925]]],[1555481721416,["28447@DESKTOP-BE7HQ26",[[1,1013,"\n"]],[1011,1011],[1012,1012]]],[1555481721608,["28447@DESKTOP-BE7HQ26",[[1,1014,"\n"]],[1012,1012],[1013,1013]]],[1555481724843,["28447@DESKTOP-BE7HQ26",[[1,1087,"\n"]],[1085,1085],[1086,1086]]],[1555481725049,["28447@DESKTOP-BE7HQ26",[[1,1088,"\n"]],[1086,1086],[1087,1087]]]],null,"28447@DESKTOP-BE7HQ26"],["60836631-f7b9-4256-8d7f-a20c3b6b7947",1556291709437,"# Spark\n\n\n\n## 1.spark优化?\n架构参数优化：shuffle，内存管理，推测执行，数据本地化：HDFS的DataNode和Spark Worker共享一台机器\n代码层面：并行度--调整finalRDD partition；缓存机制的选择--CPU使用和内存使用的权衡：checkpoint；算子的使用和选择-groupbykey，map vs mappartitions等，使用广播变量，累加器等； 序列化：压缩，存储格式的选择\n数据倾斜：重写partition规则，抽样看数据的分布，结合具体的业务\n架构的选择：统一使用yarn结合hadoop，还是使用自己的standalone计算框架\n\n## 2. spark源码-DAG-Task--任务调度部分？\nspark是粗粒度的资源申请，任务调度：sparkContext-DAGSheduler切分stage，TaskSheduler发送任务到申请好的Executor中的线程池执行\n\n## 3.submit相关配置？一般指定多大的资源？\nsubmit --master/yarn --class --deploy model clster/client\nExecutor cores 默认一个Executor 1 core，lg内存，1G，2--3个task\n\n## 4.写完spark程序如何知道多少个task？（即资源如何调配的）\n看你的并行度的设置，block的数量，web UI\n\n## 5.spark和mr性能是不是差别很多？\n一般来说Spark比Hadoop快：\n原因：\na.MR有大量的磁盘io,溢写等，Spark则可以基于内存缓存机制计算\nb.MR和Spark的资源申请的方式：粗粒度和细粒度的区别\nc.DAG计算引擎中的pipeline计算模型，MR就是MapReduce模型\nd.算子的丰富程度\n使用场景：大于pb级别的数据量一般选择MR\n生态的区别：Spark一站式的大数据处理平台，Hadoop还需要和其他的整合，升级，版本兼容等一堆问题，CDH版本如果需要更多的功能需要考虑成本的问题\n\n## 6.spark任务yarn执行流程(client)?\n\n\n\n## 7.spark运行在Yarn上流程（cluster）?\n使用场景的区别：基于yarn的好处，兼容hadoop，一套计算框架，能好的维护\n\n## 8.spark调优？\n\n\n\n## 9.shuffle主要介绍下？\nshuffle发生？---shuffle的过程---shuffle实现的选择---shuffle的优化\n\n\n\n## 10.宽窄依赖？\n看父RDD和子RR的关系，除了父RDD和子RDD一对多外，其他的都是窄依赖\n\n## 11.shuffle怎么落地的？\nshuffle的实现类型：hash Shuffle还是sortShuffle？Shuffle数据落地？\n\n## 12.Spark RDD 是什么?\n弹性分布式数据集---源码的五大特性-----RDD的计算模型：pipeline计算模型\n\n## 13.Spark算子?\nmap，flatmap，filter，foreach，first，take(n),join,cogroup,reducebykey,sortBy,distinct,mapPartition等等\n\n## 14.spark 优势？\n一栈式大数据处理平台,灵活的编程模型,相比MR速度快\n\n## 15.spark on yarn 和mapreduce中yarn有什么区别？\n没什么区别，yarn就是一个资源管理框架\n\n## 16.spark原理？\npipeline计算模型+任务调度和资源调度\n\n## 17.spark运行的job在哪里可以看到？\nDriver进程所在的节点；web UI\n\n## 18.如何监测集群中cpu，内存的使用情况，比如说：有一个spark特别占资源，特别慢，怎么排查这种情况?\nspark WEB UI；集群监控工具，找到taskid\n\n## 20.rdd的处理过程是什么，不要说概念?\n画切分Stage，pipeline的计算模型的图\n\n## 21.spark的工作流程？\nSpark的资源调度和任务调度+pipeline的计算模型\n\n## 22.SparkSQL和Spark架构，运行流程图，Spark运行的两种方式。常用的Spark函数有哪些？\nspark架构图+运行流程图(资源的调度+任务调度)+Spark client和SparkCluster+transformation算子+action算子+持久化操作算子\n\n## 23.Spark了解多少？\nspark生态-架构-运行模式+任务调度和资源调度\n\n## 24：GroupByKey的作用？\n根据key分组\n\n## Spark Sql的面试题：\n\n## 1.sparkSQL介绍下（RDD、DataFrame）\n\n关于Spark Streaming的面试题：\n\n## 2.sparkStreaming怎么跟kafka对接的,数据拉取到哪里？\n\n## 3.日流量10G没必要sparkstreaming？\n\n## 4.spark streaming 例子。问维护做过没？说sparkStreaming的维护成本很高。 我告诉他是的，比如说可能会丢数据，wal会慢。这一块儿不是我维护。没细问。\n\n## 5.spark streming调优?\n\n## 6.sparkstreaming原理？\n\n## 7.spark Streaming介绍下？和Storm比较？\n\n## 8.spark Streaming某一个task挂了，怎么解决的?\n\n## 9.spark streaming?spark的相关算法，比如推荐系统需要什么算法?\n\n## 10.park streaming工作流程？\n\n## 11.sparkstreanming没有问题，但无法计算，怎么排查问题?\n\n## 12.storm和spark streaming的区别？\n",[[1556291656418,["28447@DESKTOP-BE7HQ26",[[1,2410,"s"]],[2410,2410],[2411,2411]]]],null,"28447@DESKTOP-BE7HQ26"]]}